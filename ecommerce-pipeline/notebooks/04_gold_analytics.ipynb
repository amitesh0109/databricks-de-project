{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86197095-cdc0-4d51-90f7-f3c83f665d71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Starting Gold Layer with Azure Storage...\")\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4e7aec0-d1be-4228-958f-a16833ff8e04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get task values from Silver layer\n",
    "# Define the STORAGE_ACCOUNT variable\n",
    "STORAGE_ACCOUNT = None\n",
    "try:\n",
    "    silver_customers_count = dbutils.jobs.taskValues.get(taskKey=\"silver_processing\", key=\"silver_customers_count\", debugValue=500)\n",
    "    silver_orders_count = dbutils.jobs.taskValues.get(taskKey=\"silver_processing\", key=\"silver_orders_count\", debugValue=1000)\n",
    "    silver_quality_score = dbutils.jobs.taskValues.get(taskKey=\"silver_processing\", key=\"silver_quality_score\", debugValue=100.0)\n",
    "    silver_revenue = dbutils.jobs.taskValues.get(taskKey=\"silver_processing\", key=\"silver_revenue\", debugValue=250000.0)\n",
    "    revenue_variance = dbutils.jobs.taskValues.get(taskKey=\"silver_processing\", key=\"revenue_variance_pct\", debugValue=0.0)\n",
    "    data_retention_pct = dbutils.jobs.taskValues.get(taskKey=\"silver_processing\", key=\"data_retention_percentage\", debugValue=100.0)\n",
    "    STORAGE_ACCOUNT = dbutils.jobs.taskValues.get(taskKey=\"silver_processing\", key=\"STORAGE_ACCOUNT\", debugValue=\"dataworks\")\n",
    "    \n",
    "    # Get original data generation metrics\n",
    "    original_total_revenue = dbutils.jobs.taskValues.get(taskKey=\"data_generation\", key=\"total_revenue\", debugValue=250000.0)\n",
    "    original_avg_order_value = dbutils.jobs.taskValues.get(taskKey=\"data_generation\", key=\"avg_order_value\", debugValue=250.0)\n",
    "    original_active_customers = dbutils.jobs.taskValues.get(taskKey=\"data_generation\", key=\"active_customers\", debugValue=425)\n",
    "    \n",
    "    print(f\"ğŸ“‹ Pipeline metrics received:\")\n",
    "    print(f\"   Silver customers: {silver_customers_count}\")\n",
    "    print(f\"   Silver orders: {silver_orders_count}\")\n",
    "    print(f\"   Silver quality: {silver_quality_score}%\")\n",
    "    print(f\"   Revenue: ${silver_revenue:,.2f}\")\n",
    "    print(f\"   Data retention: {data_retention_pct:.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not retrieve Silver task values (running standalone): {e}\")\n",
    "    silver_quality_score = 100.0\n",
    "    silver_revenue = 250000.0\n",
    "\n",
    "# Authentication - Replace with your credentials\n",
    "spark.conf.set(f\"fs.azure.account.key.{STORAGE_ACCOUNT}.dfs.core.windows.net\", \"access-key\")\n",
    "\n",
    "# Azure Storage Path Configuration\n",
    "GOLD_PATH = f'abfss://gold@{STORAGE_ACCOUNT}.dfs.core.windows.net/delta/'\n",
    "\n",
    "# Create gold directory\n",
    "dbutils.fs.mkdirs(GOLD_PATH)\n",
    "\n",
    "# Database setup\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS ecommerce_gold\")\n",
    "spark.sql(\"USE ecommerce_gold\")\n",
    "\n",
    "print(f\"âœ… Gold layer configured: {GOLD_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "048d0370-c5db-4ea5-8138-6ab0bf56c327",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load Silver tables\n",
    "silver_customers = spark.table(\"ecommerce_silver.customers\")\n",
    "silver_products = spark.table(\"ecommerce_silver.products\")\n",
    "silver_orders = spark.table(\"ecommerce_silver.orders\")\n",
    "silver_order_items = spark.table(\"ecommerce_silver.order_items\")\n",
    "customer_summary = spark.table(\"ecommerce_silver.customer_summary\")\n",
    "\n",
    "print(\"âœ… Silver tables loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "513b37a6-e54a-4238-a6be-9f76b2eaa20b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sales Dashboard Analytics\n",
    "print(\"ğŸ”„ Creating sales dashboard metrics...\")\n",
    "\n",
    "sales_dashboard = (silver_orders\n",
    "    .groupBy(\"order_year\", \"order_month\", \"status\")\n",
    "    .agg(\n",
    "        F.count(\"order_id\").alias(\"order_count\"),\n",
    "        F.sum(\"total_amount\").alias(\"revenue\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        F.countDistinct(\"customer_id\").alias(\"unique_customers\"),\n",
    "        F.sum(\"shipping_cost\").alias(\"total_shipping\"),\n",
    "        F.sum(\"tax_amount\").alias(\"total_tax\"),\n",
    "        F.min(\"order_date\").alias(\"period_start\"),\n",
    "        F.max(\"order_date\").alias(\"period_end\")\n",
    "    )\n",
    "    .withColumn(\"month_year\", F.concat(F.col(\"order_year\"), F.lit(\"-\"), \n",
    "                                     F.lpad(F.col(\"order_month\"), 2, \"0\")))\n",
    "    .withColumn(\"revenue_per_customer\", F.round(F.col(\"revenue\") / F.col(\"unique_customers\"), 2))\n",
    "    .withColumn(\"shipping_rate_pct\", F.round(F.col(\"total_shipping\") / F.col(\"revenue\") * 100, 2))\n",
    ")\n",
    "\n",
    "# Save to Gold container\n",
    "sales_dashboard_path = f\"{GOLD_PATH}sales_dashboard\"\n",
    "sales_dashboard.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"order_year\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .option(\"path\", sales_dashboard_path) \\\n",
    "    .saveAsTable(\"ecommerce_gold.sales_dashboard\")\n",
    "\n",
    "sales_dashboard_count = sales_dashboard.count()\n",
    "print(f\"âœ… Sales dashboard: {sales_dashboard_count} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0baed881-0558-4b3a-8ed9-7b1c6a975a6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Customer Segmentation Analytics\n",
    "print(\"ğŸ”„ Creating customer segmentation analysis...\")\n",
    "\n",
    "customer_segments = (customer_summary\n",
    "    .withColumn(\"customer_tier\",\n",
    "        F.when(F.col(\"total_spent\") >= 1000, \"VIP\")\n",
    "        .when(F.col(\"total_spent\") >= 500, \"Premium\") \n",
    "        .when(F.col(\"total_spent\") >= 200, \"Standard\")\n",
    "        .otherwise(\"Basic\"))\n",
    "    .withColumn(\"recency_status\",\n",
    "        F.when(F.col(\"days_since_last_order\") <= 30, \"Active\")\n",
    "        .when(F.col(\"days_since_last_order\") <= 90, \"Declining\")\n",
    "        .otherwise(\"Inactive\"))\n",
    "    .withColumn(\"frequency_tier\",\n",
    "        F.when(F.col(\"total_orders\") >= 10, \"High\")\n",
    "        .when(F.col(\"total_orders\") >= 5, \"Medium\")\n",
    "        .otherwise(\"Low\"))\n",
    "    .withColumn(\"monetary_tier\",\n",
    "        F.when(F.col(\"total_spent\") >= 1000, \"High\")\n",
    "        .when(F.col(\"total_spent\") >= 300, \"Medium\")\n",
    "        .otherwise(\"Low\"))\n",
    ")\n",
    "\n",
    "segment_summary = (customer_segments\n",
    "    .groupBy(\"customer_tier\", \"recency_status\", \"segment\", \"country\")\n",
    "    .agg(\n",
    "        F.count(\"customer_id\").alias(\"customer_count\"),\n",
    "        F.sum(\"total_spent\").alias(\"total_revenue\"),\n",
    "        F.avg(\"total_spent\").alias(\"avg_customer_value\"),\n",
    "        F.avg(\"total_orders\").alias(\"avg_orders_per_customer\"),\n",
    "        F.avg(\"avg_order_value\").alias(\"avg_order_size\"),\n",
    "        F.avg(\"order_frequency\").alias(\"avg_order_frequency\")\n",
    "    )\n",
    "    .withColumn(\"revenue_per_customer\", F.round(F.col(\"total_revenue\") / F.col(\"customer_count\"), 2))\n",
    "    .withColumn(\"segment_performance_score\", \n",
    "        F.round((F.col(\"avg_customer_value\") / 100) + (F.col(\"avg_order_frequency\") * 10), 1))\n",
    ")\n",
    "\n",
    "# Save to Gold container\n",
    "customer_segments_path = f\"{GOLD_PATH}customer_segments\"\n",
    "segment_summary.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .option(\"path\", customer_segments_path) \\\n",
    "    .saveAsTable(\"ecommerce_gold.customer_segments\")\n",
    "\n",
    "customer_segments_count = segment_summary.count()\n",
    "print(f\"âœ… Customer segments: {customer_segments_count} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22e180c0-2d13-4a87-9db7-79e803221720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Product Performance Analytics\n",
    "print(\"ğŸ”„ Creating product performance analysis...\")\n",
    "\n",
    "product_performance = (silver_order_items\n",
    "    .groupBy(\"category\", \"price_category\")\n",
    "    .agg(\n",
    "        F.sum(\"line_total\").alias(\"category_revenue\"),\n",
    "        F.sum(\"profit\").alias(\"category_profit\"),\n",
    "        F.sum(\"quantity\").alias(\"units_sold\"),\n",
    "        F.countDistinct(\"order_id\").alias(\"orders_with_category\"),\n",
    "        F.countDistinct(\"product_id\").alias(\"unique_products\"),\n",
    "        F.avg(\"unit_price\").alias(\"avg_selling_price\"),\n",
    "        F.avg(\"discount_percent\").alias(\"avg_discount_percent\"),\n",
    "        F.sum(\"discount_amount\").alias(\"total_discounts_given\")\n",
    "    )\n",
    "    .withColumn(\"revenue_per_order\", F.round(F.col(\"category_revenue\") / F.col(\"orders_with_category\"), 2))\n",
    "    .withColumn(\"profit_margin_pct\", F.round(F.col(\"category_profit\") / F.col(\"category_revenue\") * 100, 2))\n",
    "    .withColumn(\"avg_units_per_order\", F.round(F.col(\"units_sold\") / F.col(\"orders_with_category\"), 2))\n",
    "    .withColumn(\"revenue_per_product\", F.round(F.col(\"category_revenue\") / F.col(\"unique_products\"), 2))\n",
    "    .withColumn(\"discount_impact_pct\", F.round(F.col(\"total_discounts_given\") / F.col(\"category_revenue\") * 100, 2))\n",
    ")\n",
    "\n",
    "# Save to Gold container\n",
    "product_performance_path = f\"{GOLD_PATH}product_performance\"\n",
    "product_performance.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .option(\"path\", product_performance_path) \\\n",
    "    .saveAsTable(\"ecommerce_gold.product_performance\")\n",
    "\n",
    "product_performance_count = product_performance.count()\n",
    "print(f\"âœ… Product performance: {product_performance_count} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d16c2a6-877c-4d78-a8cf-8285b864aa37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Executive KPIs\n",
    "print(\"ğŸ”„ Creating executive KPIs...\")\n",
    "\n",
    "executive_kpis = spark.sql(\"\"\"\n",
    "SELECT 'Overall' as period,\n",
    "    COUNT(DISTINCT order_id) as total_orders,\n",
    "    ROUND(SUM(total_amount), 2) as total_revenue,\n",
    "    COUNT(DISTINCT customer_id) as active_customers,\n",
    "    ROUND(AVG(total_amount), 2) as avg_order_value,\n",
    "    ROUND(SUM(total_amount) / COUNT(DISTINCT customer_id), 2) as revenue_per_customer,\n",
    "    COUNT(DISTINCT CASE WHEN status = 'Delivered' THEN order_id END) as completed_orders,\n",
    "    ROUND(COUNT(DISTINCT CASE WHEN status = 'Delivered' THEN order_id END) * 100.0 / COUNT(DISTINCT order_id), 2) as completion_rate_pct,\n",
    "    ROUND(SUM(shipping_cost), 2) as total_shipping_costs,\n",
    "    ROUND(SUM(tax_amount), 2) as total_tax_collected\n",
    "FROM ecommerce_silver.orders\n",
    "UNION ALL\n",
    "SELECT 'Current Month' as period,\n",
    "    COUNT(DISTINCT order_id) as total_orders,\n",
    "    ROUND(SUM(total_amount), 2) as total_revenue,\n",
    "    COUNT(DISTINCT customer_id) as active_customers,\n",
    "    ROUND(AVG(total_amount), 2) as avg_order_value,\n",
    "    ROUND(SUM(total_amount) / COUNT(DISTINCT customer_id), 2) as revenue_per_customer,\n",
    "    COUNT(DISTINCT CASE WHEN status = 'Delivered' THEN order_id END) as completed_orders,\n",
    "    ROUND(COUNT(DISTINCT CASE WHEN status = 'Delivered' THEN order_id END) * 100.0 / COUNT(DISTINCT order_id), 2) as completion_rate_pct,\n",
    "    ROUND(SUM(shipping_cost), 2) as total_shipping_costs,\n",
    "    ROUND(SUM(tax_amount), 2) as total_tax_collected\n",
    "FROM ecommerce_silver.orders \n",
    "WHERE YEAR(order_date) = YEAR(current_date()) \n",
    "    AND MONTH(order_date) = MONTH(current_date())\n",
    "\"\"\")\n",
    "\n",
    "# Save to Gold container\n",
    "executive_kpis_path = f\"{GOLD_PATH}executive_kpis\"\n",
    "executive_kpis.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .option(\"path\", executive_kpis_path) \\\n",
    "    .saveAsTable(\"ecommerce_gold.executive_kpis\")\n",
    "\n",
    "executive_kpis_count = executive_kpis.count()\n",
    "print(f\"âœ… Executive KPIs: {executive_kpis_count} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "615491ec-12aa-46ca-b646-ed9cce280b1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Monthly Trends Analysis\n",
    "print(\"ğŸ”„ Creating monthly trends analysis...\")\n",
    "\n",
    "monthly_trends = (silver_orders\n",
    "    .filter(F.col(\"status\") == \"Delivered\")\n",
    "    .groupBy(\"order_year\", \"order_month\")\n",
    "    .agg(\n",
    "        F.count(\"order_id\").alias(\"orders\"),\n",
    "        F.sum(\"total_amount\").alias(\"revenue\"),\n",
    "        F.countDistinct(\"customer_id\").alias(\"customers\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "        F.sum(\"shipping_cost\").alias(\"shipping_costs\"),\n",
    "        F.sum(\"tax_amount\").alias(\"tax_collected\"),\n",
    "        F.countDistinct(F.when(F.col(\"is_weekend\"), F.col(\"order_id\"))).alias(\"weekend_orders\")\n",
    "    )\n",
    "    .withColumn(\"month_year\", F.concat(F.col(\"order_year\"), F.lit(\"-\"), \n",
    "                                     F.lpad(F.col(\"order_month\"), 2, \"0\")))\n",
    "    .withColumn(\"revenue_per_customer\", F.round(F.col(\"revenue\") / F.col(\"customers\"), 2))\n",
    "    .withColumn(\"weekend_order_pct\", F.round(F.col(\"weekend_orders\") * 100.0 / F.col(\"orders\"), 2))\n",
    "    .orderBy(\"order_year\", \"order_month\")\n",
    ")\n",
    "\n",
    "# Save to Gold container\n",
    "monthly_trends_path = f\"{GOLD_PATH}monthly_trends\"\n",
    "monthly_trends.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .option(\"path\", monthly_trends_path) \\\n",
    "    .saveAsTable(\"ecommerce_gold.monthly_trends\")\n",
    "\n",
    "monthly_trends_count = monthly_trends.count()\n",
    "print(f\"âœ… Monthly trends: {monthly_trends_count} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afd7e69a-6660-4407-ba9d-b969e1110ace",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Performance Optimization\n",
    "print(\"âš¡ OPTIMIZING GOLD TABLES\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "optimization_results = []\n",
    "\n",
    "# Optimize all Gold tables\n",
    "gold_tables = [\n",
    "    (\"sales_dashboard\", [\"order_year\", \"order_month\"]),\n",
    "    (\"customer_segments\", [\"customer_tier\"]),\n",
    "    (\"product_performance\", [\"category\"]),\n",
    "    (\"executive_kpis\", []),\n",
    "    (\"monthly_trends\", [\"order_year\", \"order_month\"])\n",
    "]\n",
    "\n",
    "for table_name, z_order_cols in gold_tables:\n",
    "    print(f\"ğŸ”§ Optimizing ecommerce_gold.{table_name}...\")\n",
    "    \n",
    "    # Basic optimization\n",
    "    spark.sql(f\"OPTIMIZE ecommerce_gold.{table_name}\")\n",
    "    \n",
    "    # Z-ordering if columns specified\n",
    "    if z_order_cols:\n",
    "        z_order_cols_str = \", \".join(z_order_cols)\n",
    "        spark.sql(f\"OPTIMIZE ecommerce_gold.{table_name} ZORDER BY ({z_order_cols_str})\")\n",
    "        optimization_results.append(f\"{table_name}: Z-ordered by {z_order_cols_str}\")\n",
    "    else:\n",
    "        optimization_results.append(f\"{table_name}: Optimized\")\n",
    "\n",
    "print(\"âœ… All Gold tables optimized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "570827ba-31eb-41c2-9840-c5c1437ec8ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate final metrics and set task values\n",
    "gold_processing_timestamp = str(datetime.now())\n",
    "\n",
    "# Calculate total Gold records\n",
    "total_gold_records = (sales_dashboard_count + customer_segments_count + \n",
    "                     product_performance_count + executive_kpis_count + monthly_trends_count)\n",
    "\n",
    "# Get final revenue from executive KPIs\n",
    "final_revenue_overall = executive_kpis.filter(F.col(\"period\") == \"Overall\").select(\"total_revenue\").collect()[0][0]\n",
    "final_customers_overall = executive_kpis.filter(F.col(\"period\") == \"Overall\").select(\"active_customers\").collect()[0][0]\n",
    "final_avg_order_value = executive_kpis.filter(F.col(\"period\") == \"Overall\").select(\"avg_order_value\").collect()[0][0]\n",
    "completion_rate = executive_kpis.filter(F.col(\"period\") == \"Overall\").select(\"completion_rate_pct\").collect()[0][0]\n",
    "\n",
    "# Calculate pipeline efficiency metrics\n",
    "try:\n",
    "    end_to_end_data_retention = (final_customers_overall / original_active_customers * 100) if original_active_customers > 0 else 100\n",
    "    revenue_accuracy = (1 - abs(final_revenue_overall - original_total_revenue) / original_total_revenue) * 100 if original_total_revenue > 0 else 100\n",
    "except:\n",
    "    end_to_end_data_retention = 100\n",
    "    revenue_accuracy = 100\n",
    "\n",
    "# Set comprehensive task values for monitoring and reporting\n",
    "dbutils.jobs.taskValues.set(key=\"gold_total_records\", value=total_gold_records)\n",
    "dbutils.jobs.taskValues.set(key=\"gold_sales_dashboard_count\", value=sales_dashboard_count)\n",
    "dbutils.jobs.taskValues.set(key=\"gold_customer_segments_count\", value=customer_segments_count)\n",
    "dbutils.jobs.taskValues.set(key=\"gold_product_performance_count\", value=product_performance_count)\n",
    "dbutils.jobs.taskValues.set(key=\"gold_executive_kpis_count\", value=executive_kpis_count)\n",
    "dbutils.jobs.taskValues.set(key=\"gold_monthly_trends_count\", value=monthly_trends_count)\n",
    "\n",
    "# Business metrics\n",
    "dbutils.jobs.taskValues.set(key=\"final_total_revenue\", value=float(final_revenue_overall))\n",
    "dbutils.jobs.taskValues.set(key=\"final_active_customers\", value=int(final_customers_overall))\n",
    "dbutils.jobs.taskValues.set(key=\"final_avg_order_value\", value=float(final_avg_order_value))\n",
    "dbutils.jobs.taskValues.set(key=\"order_completion_rate\", value=float(completion_rate))\n",
    "\n",
    "# Pipeline quality metrics\n",
    "dbutils.jobs.taskValues.set(key=\"end_to_end_data_retention_pct\", value=float(end_to_end_data_retention))\n",
    "dbutils.jobs.taskValues.set(key=\"revenue_accuracy_pct\", value=float(revenue_accuracy))\n",
    "dbutils.jobs.taskValues.set(key=\"gold_processing_timestamp\", value=gold_processing_timestamp)\n",
    "dbutils.jobs.taskValues.set(key=\"gold_container_path\", value=f\"abfss://gold@{STORAGE_ACCOUNT}.dfs.core.windows.net/\")\n",
    "\n",
    "# Pipeline summary\n",
    "dbutils.jobs.taskValues.set(key=\"pipeline_status\", value=\"SUCCESS\")\n",
    "dbutils.jobs.taskValues.set(key=\"optimization_applied\", value=True)\n",
    "dbutils.jobs.taskValues.set(key=\"tables_optimized\", value=len(gold_tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "529687ea-bd0e-4614-955e-b78dd864b8ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display comprehensive results\n",
    "print(\"ğŸ“Š GOLD LAYER BUSINESS ANALYTICS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show executive KPIs\n",
    "print(\"ğŸ“ˆ Executive KPIs:\")\n",
    "executive_kpis.show(truncate=False)\n",
    "\n",
    "print(\"\\nğŸ¯ Top Customer Segments by Revenue:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT customer_tier, recency_status, customer_count, total_revenue, revenue_per_customer\n",
    "FROM ecommerce_gold.customer_segments \n",
    "ORDER BY total_revenue DESC \n",
    "LIMIT 5\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"\\nğŸ“¦ Top Product Categories by Performance:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT category, category_revenue, units_sold, profit_margin_pct, avg_discount_percent\n",
    "FROM ecommerce_gold.product_performance \n",
    "ORDER BY category_revenue DESC\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"\\nğŸ“… Recent Monthly Performance:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT month_year, orders, revenue, customers, avg_order_value, weekend_order_pct\n",
    "FROM ecommerce_gold.monthly_trends \n",
    "ORDER BY order_year DESC, order_month DESC\n",
    "LIMIT 6\n",
    "\"\"\").show()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Final Pipeline Summary\n",
    "print(\"ğŸ† PIPELINE EXECUTION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ“ Gold Storage: abfss://gold@{STORAGE_ACCOUNT}.dfs.core.windows.net/\")\n",
    "print(f\"ğŸ“Š Gold Records Created: {total_gold_records:,}\")\n",
    "print(f\"ğŸ’° Final Revenue: ${final_revenue_overall:,.2f}\")\n",
    "print(f\"ğŸ‘¥ Active Customers: {final_customers_overall:,}\")\n",
    "print(f\"ğŸ“ˆ Avg Order Value: ${final_avg_order_value:.2f}\")\n",
    "print(f\"âœ… Order Completion Rate: {completion_rate:.1f}%\")\n",
    "print(f\"ğŸ¯ End-to-End Data Retention: {end_to_end_data_retention:.1f}%\")\n",
    "print(f\"ğŸ’¯ Revenue Accuracy: {revenue_accuracy:.1f}%\")\n",
    "print(f\"âš¡ Tables Optimized: {len(gold_tables)}\")\n",
    "\n",
    "print(f\"\\nğŸ• Processing Timeline:\")\n",
    "try:\n",
    "    generation_time = dbutils.jobs.taskValues.get(taskKey=\"data_generation\", key=\"data_generation_timestamp\", debugValue=\"N/A\")\n",
    "    bronze_time = dbutils.jobs.taskValues.get(taskKey=\"bronze_ingestion\", key=\"bronze_ingestion_timestamp\", debugValue=\"N/A\")\n",
    "    silver_time = dbutils.jobs.taskValues.get(taskKey=\"silver_processing\", key=\"silver_processing_timestamp\", debugValue=\"N/A\")\n",
    "    print(f\"   Data Generation: {generation_time}\")\n",
    "    print(f\"   Bronze Ingestion: {bronze_time}\")\n",
    "    print(f\"   Silver Processing: {silver_time}\")\n",
    "    print(f\"   Gold Analytics: {gold_processing_timestamp}\")\n",
    "except:\n",
    "    print(\"   Individual timestamps available in job run details\")\n",
    "\n",
    "print(\"\\nâœ… Gold layer analytics complete!\")\n",
    "print(\"ğŸ“ Data stored in Azure Gold container\")\n",
    "print(\"ğŸ“‹ Comprehensive task values set for monitoring\")\n",
    "print(\"ğŸ¯ Ready for dashboard consumption!\")\n",
    "print(\"ğŸ”œ Next: Query data using 05_dashboard_queries.sql\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold Analytics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
